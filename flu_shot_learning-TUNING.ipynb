{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8.0, 8.0]\n",
    "plt.rcParams['figure.dpi'] = 140"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.read_csv('intermediate_data\\\\preprocessed_train_features.csv', index_col = 'respondent_id')\n",
    "y_train_full = pd.read_csv('input_data\\\\training_set_labels.csv', index_col = 'respondent_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = X_train_full.join(y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Trial, visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, random_state = 42, shuffle=True)\n",
    "\n",
    "for i, (trn, val) in enumerate(kf.split(train_df)):\n",
    "    train_df.loc[val, 'kfold'] = i\n",
    "    \n",
    "train_df['kfold'] = train_df['kfold'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost - H1N1 Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in X_train_full.columns.tolist() if col not in ['h1n1_vaccine', 'seasonal_vaccine']]\n",
    "target_cols = ['h1n1_vaccine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(trial):\n",
    "    roc = 0\n",
    "    for fold in range(5):\n",
    "        trn_idx = train_df['kfold'] != fold\n",
    "        val_idx = train_df['kfold'] == fold\n",
    "        trn = train_df.loc[trn_idx, :]\n",
    "        val = train_df.loc[val_idx, :]\n",
    "\n",
    "        x_tr, y_tr = trn[feature_cols].values, trn[target_cols].values\n",
    "        x_val, y_val = val[feature_cols].values, val[target_cols].values\n",
    "        \n",
    "        model, log = fit_xgb(trial, x_tr, y_tr, x_val, y_val)\n",
    "        roc += log['valid roc']/5\n",
    "        \n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def fit_xgb(trial, x_train, y_train, x_val, y_val):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [70, 75, 80, 85, 90, 95, 100]),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.025, 0.05, 0.75, 0.1]),\n",
    "        \"subsample\": trial.suggest_discrete_uniform(\"subsample\", 0.4,1,0.1),\n",
    "        \"colsample_bytree\": trial.suggest_discrete_uniform(\"colsample_bytree\", 0.8,1,0.1),\n",
    "        \"max_depth\": trial.suggest_categorical(\"max_depth\",[5,6,7,8,9,10]),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\",1,5),\n",
    "        \"gamma\": 0,\n",
    "        \"base_score\": 0.5,\n",
    "        \"random_state\": 42,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"objective\": 'reg:logistic',\n",
    "        \"tree_method\": 'exact'\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(x_train, y_train.reshape(-1,))\n",
    "\n",
    "    y_pred_tr = model.predict_proba(x_train)[:, 1]\n",
    "    y_pred_val = model.predict_proba(x_val)[:, 1]\n",
    "\n",
    "    log = {\n",
    "        \"train roc\": roc_auc_score(y_train, y_pred_tr),\n",
    "        \"valid roc\": roc_auc_score(y_val, y_pred_val)\n",
    "    }\n",
    "    \n",
    "    return model, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-01 17:11:04,234]\u001b[0m A new study created in memory with name: XGBoost H1N1 Vaccine optimization\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:11:10,674]\u001b[0m Trial 0 finished with value: 0.8349731477330505 and parameters: {'n_estimators': 80, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 0.9, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 0 with value: 0.8349731477330505.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:11:24,903]\u001b[0m Trial 1 finished with value: 0.8321322743536183 and parameters: {'n_estimators': 85, 'learning_rate': 0.025, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'max_depth': 9, 'min_child_weight': 2}. Best is trial 0 with value: 0.8349731477330505.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:11:31,326]\u001b[0m Trial 2 finished with value: 0.8302641899620713 and parameters: {'n_estimators': 75, 'learning_rate': 0.025, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 5}. Best is trial 0 with value: 0.8349731477330505.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:11:40,102]\u001b[0m Trial 3 finished with value: 0.783381173720684 and parameters: {'n_estimators': 95, 'learning_rate': 0.75, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 0 with value: 0.8349731477330505.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:11:52,569]\u001b[0m Trial 4 finished with value: 0.8290475384703468 and parameters: {'n_estimators': 70, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 1.0, 'max_depth': 9, 'min_child_weight': 3}. Best is trial 0 with value: 0.8349731477330505.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:12:01,422]\u001b[0m Trial 5 finished with value: 0.8352357097329535 and parameters: {'n_estimators': 85, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 0.9, 'max_depth': 6, 'min_child_weight': 3}. Best is trial 5 with value: 0.8352357097329535.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:12:07,251]\u001b[0m Trial 6 finished with value: 0.8029983515454435 and parameters: {'n_estimators': 75, 'learning_rate': 0.75, 'subsample': 1.0, 'colsample_bytree': 1.0, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 5 with value: 0.8352357097329535.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:12:17,640]\u001b[0m Trial 7 finished with value: 0.8339902015087206 and parameters: {'n_estimators': 75, 'learning_rate': 0.05, 'subsample': 0.5, 'colsample_bytree': 1.0, 'max_depth': 7, 'min_child_weight': 1}. Best is trial 5 with value: 0.8352357097329535.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:12:30,369]\u001b[0m Trial 8 finished with value: 0.8339504502246103 and parameters: {'n_estimators': 90, 'learning_rate': 0.025, 'subsample': 0.5, 'colsample_bytree': 0.9, 'max_depth': 8, 'min_child_weight': 4}. Best is trial 5 with value: 0.8352357097329535.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:12:42,537]\u001b[0m Trial 9 finished with value: 0.8350166099810955 and parameters: {'n_estimators': 85, 'learning_rate': 0.05, 'subsample': 0.4, 'colsample_bytree': 0.8, 'max_depth': 9, 'min_child_weight': 4}. Best is trial 5 with value: 0.8352357097329535.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "XGB_study_H1N1 = optuna.create_study(direction=\"maximize\", study_name='XGBoost H1N1 Vaccine optimization')\n",
    "XGB_study_H1N1.optimize(objective_xgb, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 85,\n",
       " 'learning_rate': 0.05,\n",
       " 'subsample': 0.9,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 3}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_study_H1N1.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path(\".\")\n",
    "\n",
    "with open(root / \"interim_data\\\\XGB_H1N1_best_params.pkl\",\"wb\") as f:\n",
    "    pickle.dump(XGB_study_H1N1.best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost - Seasonal Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in X_train_full.columns.tolist() if col not in ['h1n1_vaccine', 'seasonal_vaccine']]\n",
    "target_cols = ['seasonal_vaccine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-01 17:12:42,571]\u001b[0m A new study created in memory with name: XGBoost Seasonal Vaccine optimization\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:12:53,640]\u001b[0m Trial 0 finished with value: 0.8529467779115617 and parameters: {'n_estimators': 80, 'learning_rate': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'max_depth': 8, 'min_child_weight': 5}. Best is trial 0 with value: 0.8529467779115617.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:13:02,436]\u001b[0m Trial 1 finished with value: 0.8558622319982334 and parameters: {'n_estimators': 95, 'learning_rate': 0.05, 'subsample': 0.5, 'colsample_bytree': 0.9, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 1 with value: 0.8558622319982334.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:13:09,888]\u001b[0m Trial 2 finished with value: 0.8566159415258077 and parameters: {'n_estimators': 95, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 2 with value: 0.8566159415258077.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:13:22,558]\u001b[0m Trial 3 finished with value: 0.8489630933441223 and parameters: {'n_estimators': 75, 'learning_rate': 0.1, 'subsample': 0.5, 'colsample_bytree': 0.8, 'max_depth': 9, 'min_child_weight': 1}. Best is trial 2 with value: 0.8566159415258077.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:13:33,884]\u001b[0m Trial 4 finished with value: 0.8529842978157895 and parameters: {'n_estimators': 75, 'learning_rate': 0.1, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'max_depth': 8, 'min_child_weight': 5}. Best is trial 2 with value: 0.8566159415258077.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:13:40,548]\u001b[0m Trial 5 finished with value: 0.8230004343940723 and parameters: {'n_estimators': 80, 'learning_rate': 0.75, 'subsample': 0.9, 'colsample_bytree': 0.9, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 2 with value: 0.8566159415258077.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:13:57,064]\u001b[0m Trial 6 finished with value: 0.8516588454047211 and parameters: {'n_estimators': 80, 'learning_rate': 0.025, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.8, 'max_depth': 10, 'min_child_weight': 1}. Best is trial 2 with value: 0.8566159415258077.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:06,742]\u001b[0m Trial 7 finished with value: 0.8559381986687175 and parameters: {'n_estimators': 95, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9, 'max_depth': 6, 'min_child_weight': 3}. Best is trial 2 with value: 0.8566159415258077.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:18,547]\u001b[0m Trial 8 finished with value: 0.8043826833349557 and parameters: {'n_estimators': 75, 'learning_rate': 0.75, 'subsample': 0.9, 'colsample_bytree': 1.0, 'max_depth': 9, 'min_child_weight': 5}. Best is trial 2 with value: 0.8566159415258077.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:25,811]\u001b[0m Trial 9 finished with value: 0.8493164401541402 and parameters: {'n_estimators': 75, 'learning_rate': 0.025, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'max_depth': 5, 'min_child_weight': 3}. Best is trial 2 with value: 0.8566159415258077.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "XGB_study_SEAS = optuna.create_study(direction=\"maximize\", study_name='XGBoost Seasonal Vaccine optimization')\n",
    "XGB_study_SEAS.optimize(objective_xgb, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 95,\n",
       " 'learning_rate': 0.1,\n",
       " 'subsample': 1.0,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 2}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_study_SEAS.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root / \"interim_data\\\\XGB_SEAS_best_params.pkl\",\"wb\") as f:\n",
    "    pickle.dump(XGB_study_SEAS.best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM - H1N1 Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in X_train_full.columns.tolist() if col not in ['h1n1_vaccine', 'seasonal_vaccine']]\n",
    "target_cols = ['h1n1_vaccine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial):\n",
    "    roc = 0\n",
    "    for fold in range(5):\n",
    "        trn_idx = train_df['kfold'] != fold\n",
    "        val_idx = train_df['kfold'] == fold\n",
    "        trn = train_df.loc[trn_idx, :]\n",
    "        val = train_df.loc[val_idx, :]\n",
    "\n",
    "        x_tr, y_tr = trn[feature_cols].values, trn[target_cols].values\n",
    "        x_val, y_val = val[feature_cols].values, val[target_cols].values\n",
    "        \n",
    "        model, log = fit_lgbm(trial, x_tr, y_tr, x_val, y_val)\n",
    "        roc += log['valid roc']/5\n",
    "        \n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgbm(trial, x_train, y_train, x_val, y_val):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 60, 150, 10),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.025, 0.05, 0.75, 0.1]),\n",
    "        \"subsample\": trial.suggest_discrete_uniform(\"subsample\", 0.8,1,0.05),\n",
    "        \"colsample_bytree\": trial.suggest_discrete_uniform(\"colsample_bytree\", 0.6,0.9,0.05),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\",18,30),\n",
    "        \"min_child_weight\": trial.suggest_discrete_uniform(\"min_child_weight\",0.0005,0.0015,0.0005),\n",
    "        \"max_depth\": -1,\n",
    "        \"random_state\": 42,\n",
    "        \"silent\":True\n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(x_train, y_train.reshape(-1,))\n",
    "\n",
    "    y_pred_tr = model.predict_proba(x_train)[:, 1]\n",
    "    y_pred_val = model.predict_proba(x_val)[:, 1]\n",
    "\n",
    "    log = {\n",
    "        \"train roc\": roc_auc_score(y_train, y_pred_tr),\n",
    "        \"valid roc\": roc_auc_score(y_val, y_pred_val)\n",
    "    }\n",
    "    \n",
    "    return model, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-01 17:14:25,876]\u001b[0m A new study created in memory with name: LightGBM H1N1 Vaccine optimization\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:29,000]\u001b[0m Trial 0 finished with value: 0.8353687987493683 and parameters: {'n_estimators': 140, 'learning_rate': 0.025, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.75, 'min_child_samples': 22, 'min_child_weight': 0.0015}. Best is trial 0 with value: 0.8353687987493683.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:30,923]\u001b[0m Trial 1 finished with value: 0.7954170112453353 and parameters: {'n_estimators': 60, 'learning_rate': 0.75, 'subsample': 0.9, 'colsample_bytree': 0.6, 'min_child_samples': 22, 'min_child_weight': 0.001}. Best is trial 0 with value: 0.8353687987493683.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:33,876]\u001b[0m Trial 2 finished with value: 0.8364088239299313 and parameters: {'n_estimators': 150, 'learning_rate': 0.05, 'subsample': 0.9500000000000001, 'colsample_bytree': 0.85, 'min_child_samples': 21, 'min_child_weight': 0.0015}. Best is trial 2 with value: 0.8364088239299313.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:36,820]\u001b[0m Trial 3 finished with value: 0.8342202860182474 and parameters: {'n_estimators': 140, 'learning_rate': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'min_child_samples': 22, 'min_child_weight': 0.0015}. Best is trial 2 with value: 0.8364088239299313.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:39,410]\u001b[0m Trial 4 finished with value: 0.8351134838942817 and parameters: {'n_estimators': 120, 'learning_rate': 0.1, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.65, 'min_child_samples': 28, 'min_child_weight': 0.0015}. Best is trial 2 with value: 0.8364088239299313.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:42,438]\u001b[0m Trial 5 finished with value: 0.8369120114864268 and parameters: {'n_estimators': 140, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 0.6, 'min_child_samples': 22, 'min_child_weight': 0.001}. Best is trial 5 with value: 0.8369120114864268.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:45,511]\u001b[0m Trial 6 finished with value: 0.7838445879604106 and parameters: {'n_estimators': 150, 'learning_rate': 0.75, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.85, 'min_child_samples': 28, 'min_child_weight': 0.0005}. Best is trial 5 with value: 0.8369120114864268.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:47,575]\u001b[0m Trial 7 finished with value: 0.7807155868511085 and parameters: {'n_estimators': 110, 'learning_rate': 0.75, 'subsample': 1.0, 'colsample_bytree': 0.9, 'min_child_samples': 26, 'min_child_weight': 0.0005}. Best is trial 5 with value: 0.8369120114864268.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:49,324]\u001b[0m Trial 8 finished with value: 0.834869583435222 and parameters: {'n_estimators': 60, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.8, 'min_child_samples': 28, 'min_child_weight': 0.001}. Best is trial 5 with value: 0.8369120114864268.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:52,505]\u001b[0m Trial 9 finished with value: 0.8370858349990384 and parameters: {'n_estimators': 120, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.7, 'min_child_samples': 24, 'min_child_weight': 0.001}. Best is trial 9 with value: 0.8370858349990384.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "LGBM_study_H1N1 = optuna.create_study(direction=\"maximize\", study_name='LightGBM H1N1 Vaccine optimization')\n",
    "LGBM_study_H1N1.optimize(objective_lgbm, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 120,\n",
       " 'learning_rate': 0.05,\n",
       " 'subsample': 0.8,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'min_child_samples': 24,\n",
       " 'min_child_weight': 0.001}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBM_study_H1N1.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root / \"interim_data\\\\LGBM_H1N1_best_params.pkl\",\"wb\") as f:\n",
    "    pickle.dump(LGBM_study_H1N1.best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM - Seasonal Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in X_train_full.columns.tolist() if col not in ['h1n1_vaccine', 'seasonal_vaccine']]\n",
    "target_cols = ['seasonal_vaccine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-01 17:14:52,538]\u001b[0m A new study created in memory with name: LightGBM Seasonal Vaccine optimization\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:55,852]\u001b[0m Trial 0 finished with value: 0.8555168655183526 and parameters: {'n_estimators': 150, 'learning_rate': 0.025, 'subsample': 0.9, 'colsample_bytree': 0.8, 'min_child_samples': 23, 'min_child_weight': 0.001}. Best is trial 0 with value: 0.8555168655183526.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:14:58,503]\u001b[0m Trial 1 finished with value: 0.8564571757102681 and parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.7, 'min_child_samples': 29, 'min_child_weight': 0.0015}. Best is trial 1 with value: 0.8564571757102681.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:15:01,421]\u001b[0m Trial 2 finished with value: 0.8553481861652152 and parameters: {'n_estimators': 140, 'learning_rate': 0.025, 'subsample': 0.8, 'colsample_bytree': 0.7, 'min_child_samples': 19, 'min_child_weight': 0.0015}. Best is trial 1 with value: 0.8564571757102681.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:15:04,319]\u001b[0m Trial 3 finished with value: 0.856987393672441 and parameters: {'n_estimators': 110, 'learning_rate': 0.05, 'subsample': 0.9500000000000001, 'colsample_bytree': 0.7, 'min_child_samples': 20, 'min_child_weight': 0.001}. Best is trial 3 with value: 0.856987393672441.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:15:06,246]\u001b[0m Trial 4 finished with value: 0.8564028631875531 and parameters: {'n_estimators': 60, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'min_child_samples': 24, 'min_child_weight': 0.0005}. Best is trial 3 with value: 0.856987393672441.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:15:08,401]\u001b[0m Trial 5 finished with value: 0.8561209792033594 and parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.9500000000000001, 'colsample_bytree': 0.65, 'min_child_samples': 25, 'min_child_weight': 0.0015}. Best is trial 3 with value: 0.856987393672441.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:15:10,561]\u001b[0m Trial 6 finished with value: 0.813978560063215 and parameters: {'n_estimators': 100, 'learning_rate': 0.75, 'subsample': 1.0, 'colsample_bytree': 0.8, 'min_child_samples': 25, 'min_child_weight': 0.0005}. Best is trial 3 with value: 0.856987393672441.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:15:12,691]\u001b[0m Trial 7 finished with value: 0.8492702948348039 and parameters: {'n_estimators': 70, 'learning_rate': 0.025, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.85, 'min_child_samples': 30, 'min_child_weight': 0.0015}. Best is trial 3 with value: 0.856987393672441.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:15:14,986]\u001b[0m Trial 8 finished with value: 0.856378154685804 and parameters: {'n_estimators': 110, 'learning_rate': 0.1, 'subsample': 0.9500000000000001, 'colsample_bytree': 0.7, 'min_child_samples': 19, 'min_child_weight': 0.001}. Best is trial 3 with value: 0.856987393672441.\u001b[0m\n",
      "\u001b[32m[I 2021-02-01 17:15:18,148]\u001b[0m Trial 9 finished with value: 0.8556419389205345 and parameters: {'n_estimators': 150, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.75, 'min_child_samples': 20, 'min_child_weight': 0.0005}. Best is trial 3 with value: 0.856987393672441.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "LGBM_study_SEAS = optuna.create_study(direction=\"maximize\", study_name='LightGBM Seasonal Vaccine optimization')\n",
    "LGBM_study_SEAS.optimize(objective_lgbm, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 110,\n",
       " 'learning_rate': 0.05,\n",
       " 'subsample': 0.9500000000000001,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBM_study_SEAS.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root / \"interim_data\\\\LGBM_SEAS_best_params.pkl\",\"wb\") as f:\n",
    "    pickle.dump(LGBM_study_SEAS.best_params, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
