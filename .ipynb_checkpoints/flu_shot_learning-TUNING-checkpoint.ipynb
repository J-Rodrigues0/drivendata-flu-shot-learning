{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8.0, 8.0]\n",
    "plt.rcParams['figure.dpi'] = 140"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.read_csv('interim_data\\\\preprocessed_train_features.csv', index_col = 'respondent_id')\n",
    "y_train_full = pd.read_csv('input_data\\\\training_set_labels.csv', index_col = 'respondent_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = X_train_full.join(y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Trial, visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, random_state = 42, shuffle=True)\n",
    "\n",
    "for i, (trn, val) in enumerate(kf.split(train_df)):\n",
    "    train_df.loc[val, 'kfold'] = i\n",
    "    \n",
    "train_df['kfold'] = train_df['kfold'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost - H1N1 Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in X_train_full.columns.tolist() if col not in ['h1n1_vaccine', 'seasonal_vaccine']]\n",
    "target_cols = ['h1n1_vaccine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(trial):\n",
    "    roc = 0\n",
    "    for fold in range(5):\n",
    "        trn_idx = train_df['kfold'] != fold\n",
    "        val_idx = train_df['kfold'] == fold\n",
    "        trn = train_df.loc[trn_idx, :]\n",
    "        val = train_df.loc[val_idx, :]\n",
    "\n",
    "        x_tr, y_tr = trn[feature_cols].values, trn[target_cols].values\n",
    "        x_val, y_val = val[feature_cols].values, val[target_cols].values\n",
    "        \n",
    "        model, log = fit_xgb(trial, x_tr, y_tr, x_val, y_val)\n",
    "        roc += log['valid roc']/5\n",
    "        \n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def fit_xgb(trial, x_train, y_train, x_val, y_val):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [70, 75, 80, 85, 90, 95, 100]),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.025, 0.05, 0.75, 0.1]),\n",
    "        \"subsample\": trial.suggest_discrete_uniform(\"subsample\", 0.4,1,0.1),\n",
    "        \"colsample_bytree\": trial.suggest_discrete_uniform(\"colsample_bytree\", 0.8,1,0.1),\n",
    "        \"max_depth\": trial.suggest_categorical(\"max_depth\",[5,6,7,8,9,10]),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\",1,5),\n",
    "        \"gamma\": 0,\n",
    "        \"base_score\": 0.5,\n",
    "        \"random_state\": 42,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"objective\": 'reg:logistic',\n",
    "        \"tree_method\": 'exact'\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(x_train, y_train.reshape(-1,))\n",
    "\n",
    "    y_pred_tr = model.predict_proba(x_train)[:, 1]\n",
    "    y_pred_val = model.predict_proba(x_val)[:, 1]\n",
    "\n",
    "    log = {\n",
    "        \"train roc\": roc_auc_score(y_train, y_pred_tr),\n",
    "        \"valid roc\": roc_auc_score(y_val, y_pred_val)\n",
    "    }\n",
    "    \n",
    "    return model, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-02 17:46:35,216]\u001b[0m A new study created in memory with name: XGBoost H1N1 Vaccine optimization\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:46:43,272]\u001b[0m Trial 0 finished with value: 0.8379261257116175 and parameters: {'n_estimators': 80, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 1.0, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 0 with value: 0.8379261257116175.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:46:52,762]\u001b[0m Trial 1 finished with value: 0.8378636812159916 and parameters: {'n_estimators': 70, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 1.0, 'max_depth': 7, 'min_child_weight': 3}. Best is trial 0 with value: 0.8379261257116175.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:47:00,789]\u001b[0m Trial 2 finished with value: 0.7672444039638642 and parameters: {'n_estimators': 70, 'learning_rate': 0.75, 'subsample': 0.4, 'colsample_bytree': 0.9, 'max_depth': 6, 'min_child_weight': 4}. Best is trial 0 with value: 0.8379261257116175.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:47:16,847]\u001b[0m Trial 3 finished with value: 0.8360287467028579 and parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 0.6000000000000001, 'colsample_bytree': 1.0, 'max_depth': 8, 'min_child_weight': 3}. Best is trial 0 with value: 0.8379261257116175.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:47:34,060]\u001b[0m Trial 4 finished with value: 0.7728570507003893 and parameters: {'n_estimators': 90, 'learning_rate': 0.75, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.9, 'max_depth': 10, 'min_child_weight': 1}. Best is trial 0 with value: 0.8379261257116175.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:47:42,145]\u001b[0m Trial 5 finished with value: 0.8320389915920566 and parameters: {'n_estimators': 75, 'learning_rate': 0.025, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'max_depth': 5, 'min_child_weight': 5}. Best is trial 0 with value: 0.8379261257116175.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:47:54,087]\u001b[0m Trial 6 finished with value: 0.839916108349082 and parameters: {'n_estimators': 100, 'learning_rate': 0.05, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_weight': 2}. Best is trial 6 with value: 0.839916108349082.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:48:02,720]\u001b[0m Trial 7 finished with value: 0.840332643349887 and parameters: {'n_estimators': 95, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.9, 'max_depth': 6, 'min_child_weight': 4}. Best is trial 7 with value: 0.840332643349887.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:48:13,446]\u001b[0m Trial 8 finished with value: 0.8350004666129601 and parameters: {'n_estimators': 70, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.9, 'max_depth': 9, 'min_child_weight': 1}. Best is trial 7 with value: 0.840332643349887.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:48:20,197]\u001b[0m Trial 9 finished with value: 0.7973293017284742 and parameters: {'n_estimators': 70, 'learning_rate': 0.75, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.8, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 7 with value: 0.840332643349887.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "XGB_study_H1N1 = optuna.create_study(direction=\"maximize\", study_name='XGBoost H1N1 Vaccine optimization')\n",
    "XGB_study_H1N1.optimize(objective_xgb, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 95,\n",
       " 'learning_rate': 0.1,\n",
       " 'subsample': 1.0,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 4}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_study_H1N1.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path(\".\")\n",
    "\n",
    "with open(root / \"interim_data\\\\XGB_H1N1_best_params.pkl\",\"wb\") as f:\n",
    "    pickle.dump(XGB_study_H1N1.best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost - Seasonal Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in X_train_full.columns.tolist() if col not in ['h1n1_vaccine', 'seasonal_vaccine']]\n",
    "target_cols = ['seasonal_vaccine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-02 17:48:20,296]\u001b[0m A new study created in memory with name: XGBoost Seasonal Vaccine optimization\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:48:32,730]\u001b[0m Trial 0 finished with value: 0.8547169032550593 and parameters: {'n_estimators': 75, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'max_depth': 10, 'min_child_weight': 2}. Best is trial 0 with value: 0.8547169032550593.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:48:49,119]\u001b[0m Trial 1 finished with value: 0.8553089428257645 and parameters: {'n_estimators': 95, 'learning_rate': 0.025, 'subsample': 0.9, 'colsample_bytree': 0.8, 'max_depth': 10, 'min_child_weight': 3}. Best is trial 1 with value: 0.8553089428257645.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:49:05,556]\u001b[0m Trial 2 finished with value: 0.8197279286550491 and parameters: {'n_estimators': 95, 'learning_rate': 0.75, 'subsample': 1.0, 'colsample_bytree': 1.0, 'max_depth': 10, 'min_child_weight': 2}. Best is trial 1 with value: 0.8553089428257645.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:49:21,054]\u001b[0m Trial 3 finished with value: 0.8530545331056192 and parameters: {'n_estimators': 80, 'learning_rate': 0.1, 'subsample': 0.9, 'colsample_bytree': 1.0, 'max_depth': 10, 'min_child_weight': 1}. Best is trial 1 with value: 0.8553089428257645.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:49:36,591]\u001b[0m Trial 4 finished with value: 0.809081409017611 and parameters: {'n_estimators': 90, 'learning_rate': 0.75, 'subsample': 0.8, 'colsample_bytree': 0.8, 'max_depth': 10, 'min_child_weight': 2}. Best is trial 1 with value: 0.8553089428257645.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:49:45,948]\u001b[0m Trial 5 finished with value: 0.853518474158596 and parameters: {'n_estimators': 70, 'learning_rate': 0.025, 'subsample': 0.5, 'colsample_bytree': 1.0, 'max_depth': 6, 'min_child_weight': 1}. Best is trial 1 with value: 0.8553089428257645.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:49:55,528]\u001b[0m Trial 6 finished with value: 0.8590269438893088 and parameters: {'n_estimators': 85, 'learning_rate': 0.05, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.8, 'max_depth': 6, 'min_child_weight': 5}. Best is trial 6 with value: 0.8590269438893088.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:06,340]\u001b[0m Trial 7 finished with value: 0.8553628557151314 and parameters: {'n_estimators': 80, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.8, 'max_depth': 9, 'min_child_weight': 2}. Best is trial 6 with value: 0.8590269438893088.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:18,091]\u001b[0m Trial 8 finished with value: 0.7865055785140322 and parameters: {'n_estimators': 75, 'learning_rate': 0.75, 'subsample': 0.4, 'colsample_bytree': 1.0, 'max_depth': 8, 'min_child_weight': 4}. Best is trial 6 with value: 0.8590269438893088.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:27,573]\u001b[0m Trial 9 finished with value: 0.86001391719132 and parameters: {'n_estimators': 85, 'learning_rate': 0.1, 'subsample': 0.5, 'colsample_bytree': 1.0, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 9 with value: 0.86001391719132.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "XGB_study_SEAS = optuna.create_study(direction=\"maximize\", study_name='XGBoost Seasonal Vaccine optimization')\n",
    "XGB_study_SEAS.optimize(objective_xgb, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 85,\n",
       " 'learning_rate': 0.1,\n",
       " 'subsample': 0.5,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_study_SEAS.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root / \"interim_data\\\\XGB_SEAS_best_params.pkl\",\"wb\") as f:\n",
    "    pickle.dump(XGB_study_SEAS.best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM - H1N1 Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in X_train_full.columns.tolist() if col not in ['h1n1_vaccine', 'seasonal_vaccine']]\n",
    "target_cols = ['h1n1_vaccine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial):\n",
    "    roc = 0\n",
    "    for fold in range(5):\n",
    "        trn_idx = train_df['kfold'] != fold\n",
    "        val_idx = train_df['kfold'] == fold\n",
    "        trn = train_df.loc[trn_idx, :]\n",
    "        val = train_df.loc[val_idx, :]\n",
    "\n",
    "        x_tr, y_tr = trn[feature_cols].values, trn[target_cols].values\n",
    "        x_val, y_val = val[feature_cols].values, val[target_cols].values\n",
    "        \n",
    "        model, log = fit_lgbm(trial, x_tr, y_tr, x_val, y_val)\n",
    "        roc += log['valid roc']/5\n",
    "        \n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgbm(trial, x_train, y_train, x_val, y_val):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 60, 150, 10),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.025, 0.05, 0.75, 0.1]),\n",
    "        \"subsample\": trial.suggest_discrete_uniform(\"subsample\", 0.8,1,0.05),\n",
    "        \"colsample_bytree\": trial.suggest_discrete_uniform(\"colsample_bytree\", 0.6,0.9,0.05),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\",18,30),\n",
    "        \"min_child_weight\": trial.suggest_discrete_uniform(\"min_child_weight\",0.0005,0.0015,0.0005),\n",
    "        \"max_depth\": -1,\n",
    "        \"random_state\": 42,\n",
    "        \"silent\":True\n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(x_train, y_train.reshape(-1,))\n",
    "\n",
    "    y_pred_tr = model.predict_proba(x_train)[:, 1]\n",
    "    y_pred_val = model.predict_proba(x_val)[:, 1]\n",
    "\n",
    "    log = {\n",
    "        \"train roc\": roc_auc_score(y_train, y_pred_tr),\n",
    "        \"valid roc\": roc_auc_score(y_val, y_pred_val)\n",
    "    }\n",
    "    \n",
    "    return model, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-02 17:50:27,693]\u001b[0m A new study created in memory with name: LightGBM H1N1 Vaccine optimization\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:30,211]\u001b[0m Trial 0 finished with value: 0.8402824674909661 and parameters: {'n_estimators': 150, 'learning_rate': 0.025, 'subsample': 0.9500000000000001, 'colsample_bytree': 0.6, 'min_child_samples': 23, 'min_child_weight': 0.001}. Best is trial 0 with value: 0.8402824674909661.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:32,296]\u001b[0m Trial 1 finished with value: 0.8390352056839456 and parameters: {'n_estimators': 120, 'learning_rate': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.75, 'min_child_samples': 18, 'min_child_weight': 0.0015}. Best is trial 0 with value: 0.8402824674909661.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:33,895]\u001b[0m Trial 2 finished with value: 0.8348162617675492 and parameters: {'n_estimators': 60, 'learning_rate': 0.025, 'subsample': 0.8, 'colsample_bytree': 0.6, 'min_child_samples': 28, 'min_child_weight': 0.0015}. Best is trial 0 with value: 0.8402824674909661.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:35,606]\u001b[0m Trial 3 finished with value: 0.7980633862131253 and parameters: {'n_estimators': 90, 'learning_rate': 0.75, 'subsample': 0.8, 'colsample_bytree': 0.7, 'min_child_samples': 23, 'min_child_weight': 0.0015}. Best is trial 0 with value: 0.8402824674909661.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:38,124]\u001b[0m Trial 4 finished with value: 0.8395334831907315 and parameters: {'n_estimators': 150, 'learning_rate': 0.025, 'subsample': 0.9, 'colsample_bytree': 0.8, 'min_child_samples': 19, 'min_child_weight': 0.0015}. Best is trial 0 with value: 0.8402824674909661.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:39,751]\u001b[0m Trial 5 finished with value: 0.7937752507076552 and parameters: {'n_estimators': 80, 'learning_rate': 0.75, 'subsample': 0.9500000000000001, 'colsample_bytree': 0.65, 'min_child_samples': 26, 'min_child_weight': 0.001}. Best is trial 0 with value: 0.8402824674909661.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:42,138]\u001b[0m Trial 6 finished with value: 0.8392954383657595 and parameters: {'n_estimators': 140, 'learning_rate': 0.025, 'subsample': 0.9500000000000001, 'colsample_bytree': 0.8, 'min_child_samples': 29, 'min_child_weight': 0.001}. Best is trial 0 with value: 0.8402824674909661.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:43,677]\u001b[0m Trial 7 finished with value: 0.7928733659990184 and parameters: {'n_estimators': 70, 'learning_rate': 0.75, 'subsample': 0.9, 'colsample_bytree': 0.8, 'min_child_samples': 23, 'min_child_weight': 0.001}. Best is trial 0 with value: 0.8402824674909661.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:45,221]\u001b[0m Trial 8 finished with value: 0.8325661197806075 and parameters: {'n_estimators': 60, 'learning_rate': 0.025, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.85, 'min_child_samples': 28, 'min_child_weight': 0.0005}. Best is trial 0 with value: 0.8402824674909661.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:47,174]\u001b[0m Trial 9 finished with value: 0.8407692119015766 and parameters: {'n_estimators': 110, 'learning_rate': 0.1, 'subsample': 0.9500000000000001, 'colsample_bytree': 0.65, 'min_child_samples': 25, 'min_child_weight': 0.0005}. Best is trial 9 with value: 0.8407692119015766.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "LGBM_study_H1N1 = optuna.create_study(direction=\"maximize\", study_name='LightGBM H1N1 Vaccine optimization')\n",
    "LGBM_study_H1N1.optimize(objective_lgbm, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 110,\n",
       " 'learning_rate': 0.1,\n",
       " 'subsample': 0.9500000000000001,\n",
       " 'colsample_bytree': 0.65,\n",
       " 'min_child_samples': 25,\n",
       " 'min_child_weight': 0.0005}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBM_study_H1N1.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root / \"interim_data\\\\LGBM_H1N1_best_params.pkl\",\"wb\") as f:\n",
    "    pickle.dump(LGBM_study_H1N1.best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM - Seasonal Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in X_train_full.columns.tolist() if col not in ['h1n1_vaccine', 'seasonal_vaccine']]\n",
    "target_cols = ['seasonal_vaccine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-02 17:50:47,253]\u001b[0m A new study created in memory with name: LightGBM Seasonal Vaccine optimization\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:48,865]\u001b[0m Trial 0 finished with value: 0.8603412004776719 and parameters: {'n_estimators': 70, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'min_child_weight': 0.001}. Best is trial 0 with value: 0.8603412004776719.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:50,457]\u001b[0m Trial 1 finished with value: 0.8567349212334133 and parameters: {'n_estimators': 60, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 0.75, 'min_child_samples': 24, 'min_child_weight': 0.0005}. Best is trial 0 with value: 0.8603412004776719.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:52,503]\u001b[0m Trial 2 finished with value: 0.8599948056317894 and parameters: {'n_estimators': 110, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.75, 'min_child_samples': 29, 'min_child_weight': 0.001}. Best is trial 0 with value: 0.8603412004776719.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:55,032]\u001b[0m Trial 3 finished with value: 0.8582592123976432 and parameters: {'n_estimators': 140, 'learning_rate': 0.025, 'subsample': 0.9, 'colsample_bytree': 0.6, 'min_child_samples': 18, 'min_child_weight': 0.0015}. Best is trial 0 with value: 0.8603412004776719.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:57,485]\u001b[0m Trial 4 finished with value: 0.8582592123976432 and parameters: {'n_estimators': 140, 'learning_rate': 0.025, 'subsample': 0.8, 'colsample_bytree': 0.6, 'min_child_samples': 18, 'min_child_weight': 0.001}. Best is trial 0 with value: 0.8603412004776719.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:50:59,248]\u001b[0m Trial 5 finished with value: 0.858328651131952 and parameters: {'n_estimators': 70, 'learning_rate': 0.05, 'subsample': 0.9500000000000001, 'colsample_bytree': 0.6, 'min_child_samples': 22, 'min_child_weight': 0.001}. Best is trial 0 with value: 0.8603412004776719.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:51:01,379]\u001b[0m Trial 6 finished with value: 0.8600685831748208 and parameters: {'n_estimators': 110, 'learning_rate': 0.05, 'subsample': 0.9500000000000001, 'colsample_bytree': 0.9, 'min_child_samples': 24, 'min_child_weight': 0.0015}. Best is trial 0 with value: 0.8603412004776719.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:51:03,800]\u001b[0m Trial 7 finished with value: 0.8606860639040799 and parameters: {'n_estimators': 140, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 0.75, 'min_child_samples': 21, 'min_child_weight': 0.0015}. Best is trial 7 with value: 0.8606860639040799.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:51:05,394]\u001b[0m Trial 8 finished with value: 0.8507126294604914 and parameters: {'n_estimators': 60, 'learning_rate': 0.025, 'subsample': 1.0, 'colsample_bytree': 0.75, 'min_child_samples': 18, 'min_child_weight': 0.0005}. Best is trial 7 with value: 0.8606860639040799.\u001b[0m\n",
      "\u001b[32m[I 2021-02-02 17:51:07,519]\u001b[0m Trial 9 finished with value: 0.8602711505279876 and parameters: {'n_estimators': 100, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 0.6, 'min_child_samples': 29, 'min_child_weight': 0.0015}. Best is trial 7 with value: 0.8606860639040799.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "LGBM_study_SEAS = optuna.create_study(direction=\"maximize\", study_name='LightGBM Seasonal Vaccine optimization')\n",
    "LGBM_study_SEAS.optimize(objective_lgbm, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 140,\n",
       " 'learning_rate': 0.05,\n",
       " 'subsample': 0.9,\n",
       " 'colsample_bytree': 0.75,\n",
       " 'min_child_samples': 21,\n",
       " 'min_child_weight': 0.0015}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBM_study_SEAS.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root / \"interim_data\\\\LGBM_SEAS_best_params.pkl\",\"wb\") as f:\n",
    "    pickle.dump(LGBM_study_SEAS.best_params, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
